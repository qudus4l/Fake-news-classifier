{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4af5236",
   "metadata": {},
   "source": [
    "# Create a fake news classifier\n",
    "\n",
    "The rise of social media and the proliferation of digital news sources have made it easier than ever to spread misinformation and fake news. As a result, this prompts the need to be able to distinguish between real and fake news stories. Machine learning techniques offer a promising solution to this, by allowing us to classify news articles based on their content and other features.\n",
    "\n",
    "In this project, I will explore the use of machine learning classification methods to classify news articles as either real or fake. I will analyse the text of the news articles based on the natural language processing (NLP) methods, and evaluate the performance of our classifier using a variety of metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe4d3d",
   "metadata": {},
   "source": [
    "##### Part 1: Data Preprocessing using NLP Techniques\n",
    "\n",
    "In this first section, I will first perform some exploratory data analysis on the data provided, and preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2052f9c",
   "metadata": {},
   "source": [
    "1. Import the necesary libraries and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf12dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab298ea5",
   "metadata": {},
   "source": [
    "2. Read the dataset from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d8c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_news_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffac5",
   "metadata": {},
   "source": [
    "3. After loading the dataset, perform some primary exploratory data analysis to understand the dataset provided. You can use simple pandas methods and attributes such as `head()`, `shape` and `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffa7b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title   \n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...  \\\n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2   2                  Why the Truth Might Get You Fired   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4   4  Iranian woman jailed for fictional unpublished...   \n",
       "5   5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "6   6  Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
       "7   7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "8   8  Excerpts From a Draft Script for Donald Trump’...   \n",
       "9   9  A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "\n",
       "                         author   \n",
       "0                 Darrell Lucus  \\\n",
       "1               Daniel J. Flynn   \n",
       "2            Consortiumnews.com   \n",
       "3               Jessica Purkiss   \n",
       "4                Howard Portnoy   \n",
       "5               Daniel Nussbaum   \n",
       "6                           NaN   \n",
       "7               Alissa J. Rubin   \n",
       "8                           NaN   \n",
       "9  Megan Twohey and Scott Shane   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "5  In these trying times, Jackie Mason is the Voi...      0  \n",
       "6  Ever wonder how Britain’s most iconic pop pian...      1  \n",
       "7  PARIS  —   France chose an idealistic, traditi...      0  \n",
       "8  Donald J. Trump is scheduled to make a highly ...      0  \n",
       "9  A week before Michael T. Flynn resigned as nat...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis to familiarize yourself with the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f8454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78308fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  20800.000000  20800.000000\n",
       "mean   10399.500000      0.500625\n",
       "std     6004.587135      0.500012\n",
       "min        0.000000      0.000000\n",
       "25%     5199.750000      0.000000\n",
       "50%    10399.500000      1.000000\n",
       "75%    15599.250000      1.000000\n",
       "max    20799.000000      1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0979e",
   "metadata": {},
   "source": [
    "4. Before proceeding, it is always a good measure to check if null values are present in the dataset or not. \n",
    "\n",
    "If there are null values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa589935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and if any, fill them with an empty string \n",
    "df.isnull().sum()\n",
    "# Use the `fillna` method to fill the null values with an empty string\n",
    "df.fillna(\"\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23c16",
   "metadata": {},
   "source": [
    "5. For data preprocessing, I will focus on the 'text' column of the DataFrame, which contains the content of each news article. I will apply tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e14b15c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to tokenize the text given\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize_text function to the 'text' column of the DataFrame and create a new column 'tokenized_text'\n",
    "df['tokenized_text'] = df['text'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0fb96",
   "metadata": {},
   "source": [
    "6. With the new column containing the tokens of the text, I will dive into the second preprocessing step, which is to remove the stop words from the tokens.\n",
    "\n",
    "A list will be created- `stop_words` that contains the NLTK predefined stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec139f81",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13f3e2",
   "metadata": {},
   "source": [
    "7. Define a function that removes stop words from a list of tokens. The NLTK predefined stopwords are in lowercase, while some of the tokens in your current DataFrame contain uppercase alphabets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e06c12",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    tokens_without_stopwords = [i for i in tokens if i.lower() not in stop_words]\n",
    "    return tokens_without_stopwords\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tokenized_text' column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0083e9",
   "metadata": {},
   "source": [
    "##### Part 2: Separating the dataset and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3fba8",
   "metadata": {},
   "source": [
    "8. Before proceeding, I will separate the dataset into features and targets. This allows to clearly define the inputs and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8928d91f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the data into features and targets\n",
    "X_df = df['tokenized_text']\n",
    "y_df = df['label']\n",
    "#Analyse the `y_df` data.\n",
    "type(y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270e470",
   "metadata": {},
   "source": [
    "9. The data type of y_df appears to be a `str` or `object` data type.\n",
    "\n",
    "We are looking to have a binary output which should only include numerical values. To train the model, I will  convert the label column into a numerical one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70162a20",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_df = y_df.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360c894",
   "metadata": {},
   "source": [
    "10. As machine learning models take in numerical values for their inputs, I have to convert the feature data into numerical format as well. This is where vectorization will be incorporated.\n",
    "\n",
    "Import the `TfidfVectorizer` and create a TfidfVectorizer object. Since the features being worked with are in tokens, I will specify this in the parameter as the vectorizer takes in strings by default.\n",
    "\n",
    "I will set the `tokenizer` parameter to a lambda function that simply returns each document as-is. Also set `lowercase=False` to ensure that the tokenization is not modified.\n",
    "\n",
    "After this, I can fit and transform the vectorizer on the tokenized documents `x_df`. This produces the TFIDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e065ab89",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Q/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform vectorization using the TFIDF Vectorizer and fit and transform the tokenized documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569c369",
   "metadata": {},
   "source": [
    "##### Part 3: Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec5c74",
   "metadata": {},
   "source": [
    "11. I will be making use of a `LogisticRegression` model to create the fake news classifier.\n",
    "\n",
    "I will first split the data into a training set and a testing set to evaluate the performance of the Logistic Regression model.\n",
    "\n",
    "Now with the TFIDF matrix and target data, I can split the data into testing and training sets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002fa916",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, y_df, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac8fff",
   "metadata": {},
   "source": [
    "12. Import the necessary modules and create a LogisticRegression object then fit the model according to the X and y training data produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8254cf81",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87090ab2",
   "metadata": {},
   "source": [
    "13. Now that the model has been trained, I will calculate the predictions of the model using the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a75376",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2333ef",
   "metadata": {},
   "source": [
    "14. Now, to evaluate how well the model did. Here, I will use three evaluation metrics to assess the performance of the model. These are the metrics I will be working with: Accuracy, Precision and Recall.\n",
    "\n",
    "I will import the following metrics and calculate the scores by comparing the test targets to the predicted targets of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334f02c1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ce86b",
   "metadata": {},
   "source": [
    "By using multiple metrics for evaluation, we can identify the strengths and weaknesses of the model to make informed decisions about how to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aaca2",
   "metadata": {},
   "source": [
    "15. Print out each of the scores for your model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a782fbf8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9651923076923077\n",
      "The precision score is  0.9661982529434106\n",
      "The recall score is  0.9650986342943855\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy score is \", accuracy)\n",
    "print(\"The precision score is \", precision)\n",
    "print(\"The recall score is \", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
